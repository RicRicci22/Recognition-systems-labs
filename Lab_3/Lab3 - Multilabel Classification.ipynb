{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MULTILABEL CLASSIFICATION\n",
    "\n",
    "A multilabel setting is identified by samples that can simultaneously belong to more than one class. For example,  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref                                                             title                                               size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
      "--------------------------------------------------------------  -------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
      "rahulvyasm/netflix-movies-and-tv-shows                          Netflix Movies and TV Shows                          1MB  2024-04-10 09:48:38          14187        300  1.0              \n",
      "kapturovalexander/time-series-for-online-store                  üè™üè¨ü™´ Electronic store sales data                      9MB  2024-04-30 09:33:41            805         26  1.0              \n",
      "sahirmaharajj/school-student-daily-attendance                   School Student Daily Attendance                      2MB  2024-04-29 19:29:56           2262         47  1.0              \n",
      "jaidalmotra/pokemon-dataset                                     Pokemon Dataset                                     19KB  2024-04-30 10:38:36           1318         38  1.0              \n",
      "muhammadibrahimqasmi/airbnb-stock-dataset-2020-24               Airbnb (ABNB) Stock Data üìà                          18KB  2024-05-04 20:29:32            290         34  1.0              \n",
      "fahadrehman07/retail-transaction-dataset                        Retail Transaction Dataset                           5MB  2024-05-01 10:05:25           1558         43  1.0              \n",
      "mexwell/heart-disease-dataset                                   ü´Ä Heart Disease Dataset                            399KB  2024-04-08 09:43:49           6427        103  1.0              \n",
      "jancsg/cybersecurity-suspicious-web-threat-interactions         Cybersecurity: Suspicious Web Threat Interactions    4KB  2024-04-27 08:43:34            852         24  1.0              \n",
      "rabieelkharoua/predict-survival-of-patients-with-heart-failure  Predict survival of patients with heart failure      4KB  2024-04-25 10:21:47           2437         43  1.0              \n",
      "aadarshvelu/aids-virus-infection-prediction                     AIDS Virus Infection Prediction üíâ                    2MB  2024-04-28 03:22:18           1587         44  1.0              \n",
      "anandshaw2001/airlines-booking-csv                              Airlines_Booking.csv                               414KB  2024-04-20 17:38:50           2528         35  1.0              \n",
      "sujithmandala/second-hand-car-price-prediction                  Second Hand Car Price Prediction                     2KB  2024-04-24 12:09:30           2260         38  1.0              \n",
      "gucci1337/weather-of-albania-last-three-years                   Weather.csv                                         32KB  2024-05-02 20:27:18            517         23  1.0              \n",
      "adityakishor1/vehicle-sales-count-by-year-2002-2023             Vehicle_Sales_Count by Year 2002-2023                5KB  2024-04-20 09:33:07           1349         34  1.0              \n",
      "dansbecker/melbourne-housing-snapshot                           Melbourne Housing Snapshot                         451KB  2018-06-05 12:52:24         146101       1471  0.7058824        \n",
      "chopper53/machine-learning-engineer-salary-in-2024              Machine Learning Engineer Salary in 2024           107KB  2024-04-23 17:30:13           2052         48  1.0              \n",
      "prishasawhney/mushroom-dataset                                  Mushroom Dataset (Binary Classification)           602KB  2024-04-18 19:56:44           2842         77  1.0              \n",
      "imtkaggleteam/pharmacies                                        Pharmacies                                           7MB  2024-05-03 12:00:45            439         33  1.0              \n",
      "brianblakely/top-100-songs-and-lyrics-from-1959-to-2019         Top 100 Songs & Lyrics By Year 1959 - 2023 (USA)    24MB  2024-04-28 18:59:05            737         30  1.0              \n",
      "mikhail1681/airline-quality-ratings                             Airline Quality Ratings                              2MB  2024-05-01 10:23:05            428         41  1.0              \n"
     ]
    }
   ],
   "source": [
    "# Download the dataset\n",
    "!kaggle datasets list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/shivanandmn/multilabel-classification-dataset\n",
      "License(s): other\n",
      "Downloading multilabel-classification-dataset.zip to c:\\Users\\Riccardo\\Desktop\\Dottorato\\Ricerca\\Terzo anno\\Recognition systems - tutorato\\Laboratori\\Recognition-systems-labs\\Lab_3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/11.4M [00:00<?, ?B/s]\n",
      "  9%|‚ñä         | 1.00M/11.4M [00:00<00:04, 2.43MB/s]\n",
      " 17%|‚ñà‚ñã        | 2.00M/11.4M [00:00<00:02, 3.70MB/s]\n",
      " 26%|‚ñà‚ñà‚ñå       | 3.00M/11.4M [00:00<00:01, 4.59MB/s]\n",
      " 35%|‚ñà‚ñà‚ñà‚ñç      | 4.00M/11.4M [00:00<00:01, 5.48MB/s]\n",
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 5.00M/11.4M [00:01<00:01, 6.22MB/s]\n",
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 6.00M/11.4M [00:01<00:00, 6.56MB/s]\n",
      " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 7.00M/11.4M [00:01<00:00, 7.07MB/s]\n",
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 8.00M/11.4M [00:01<00:00, 7.15MB/s]\n",
      " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 9.00M/11.4M [00:01<00:00, 7.61MB/s]\n",
      " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 10.0M/11.4M [00:01<00:00, 7.69MB/s]\n",
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 11.0M/11.4M [00:01<00:00, 7.89MB/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11.4M/11.4M [00:01<00:00, 6.38MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d shivanandmn/multilabel-classification-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xf multilabel-classification-dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Reconstructing Subject-Specific Effect Maps</td>\n",
       "      <td>Predictive models allow subject-specific inf...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Rotation Invariance Neural Network</td>\n",
       "      <td>Rotation invariance and translation invarian...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n",
       "      <td>We introduce and develop the notion of spher...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A finite element approximation for the stochas...</td>\n",
       "      <td>The stochastic Landau--Lifshitz--Gilbert (LL...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Comparative study of Discrete Wavelet Transfor...</td>\n",
       "      <td>Fourier-transform infra-red (FTIR) spectra o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                              TITLE  \\\n",
       "0   1        Reconstructing Subject-Specific Effect Maps   \n",
       "1   2                 Rotation Invariance Neural Network   \n",
       "2   3  Spherical polyharmonics and Poisson kernels fo...   \n",
       "3   4  A finite element approximation for the stochas...   \n",
       "4   5  Comparative study of Discrete Wavelet Transfor...   \n",
       "\n",
       "                                            ABSTRACT  Computer Science  \\\n",
       "0    Predictive models allow subject-specific inf...                 1   \n",
       "1    Rotation invariance and translation invarian...                 1   \n",
       "2    We introduce and develop the notion of spher...                 0   \n",
       "3    The stochastic Landau--Lifshitz--Gilbert (LL...                 0   \n",
       "4    Fourier-transform infra-red (FTIR) spectra o...                 1   \n",
       "\n",
       "   Physics  Mathematics  Statistics  Quantitative Biology  \\\n",
       "0        0            0           0                     0   \n",
       "1        0            0           0                     0   \n",
       "2        0            1           0                     0   \n",
       "3        0            1           0                     0   \n",
       "4        0            0           1                     0   \n",
       "\n",
       "   Quantitative Finance  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's start to explore the dataset\n",
    "import pandas as pd\n",
    "df = pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully, total number of train samples: 20972\n"
     ]
    }
   ],
   "source": [
    "# First of all, we have to create the dataset\n",
    "from dataset import MultiLabelDataset\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "dataset = MultiLabelDataset(data_path=\"train.csv\", split='train')\n",
    "# Split the two in train and validation\n",
    "train_dataset, val_dataset = random_split(dataset, [int(len(dataset)*0.9), len(dataset) - int(len(dataset)*0.9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the network. We will start with a simple RNN based model. \n",
    "from model import SimpleRNNModel\n",
    "import json\n",
    "\n",
    "word_2_idx = json.load(open('w2i.json'))\n",
    "# HYPER PARAMETERS\n",
    "embedding_dim = 100\n",
    "hidden_dim = 256\n",
    "output_dim = dataset.__getnlabels__()\n",
    "pad_idx = 0\n",
    "vocab_size = len(word_2_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 590/590 [00:12<00:00, 47.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 590/590 [00:11<00:00, 49.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 590/590 [00:12<00:00, 47.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 590/590 [00:12<00:00, 47.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 590/590 [00:16<00:00, 35.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 590/590 [00:18<00:00, 32.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 590/590 [00:17<00:00, 33.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 590/590 [00:18<00:00, 32.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 590/590 [00:17<00:00, 32.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 590/590 [00:16<00:00, 36.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# TRAIN LOOP \n",
    "# HYPERPARAMETERS\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "# Model \n",
    "model = SimpleRNNModel(embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_dim=output_dim, vocab_size=vocab_size, pad_idx=pad_idx)\n",
    "# Send the model to the GPU \n",
    "model.to(DEVICE)\n",
    "\n",
    "# Create the dataloaders\n",
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)\n",
    "\n",
    "# Create the optimizer\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "\n",
    "# Create the loss function\n",
    "import torch.nn as nn\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "from tqdm import tqdm\n",
    "from utils import convert_texts_to_indices\n",
    "\n",
    "# Send the model to the GPU\n",
    "model.train()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = 0\n",
    "    for batch in tqdm(train_loader):\n",
    "        titles, abst, labels = batch\n",
    "        labels = labels.to(DEVICE)\n",
    "        # Prepare the titles\n",
    "        titles_batch = convert_texts_to_indices(texts=titles,word2idx=word_2_idx,pad_idx=pad_idx)\n",
    "        titles_batch = titles_batch.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(titles_batch)\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    print(\"Training loss: {}\".format(round(train_loss/len(train_loader),4)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1049/1049 [00:03<00:00, 346.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.3798\n",
      "Validation accuracy: 0.5214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the validation loss and accuracy \n",
    "\n",
    "BATCH_SIZE = 2\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)\n",
    "\n",
    "model.eval()\n",
    "val_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_loader):\n",
    "        titles, abst, labels = batch\n",
    "        labels = labels.to(DEVICE)\n",
    "        # Prepare the titles\n",
    "        titles_batch = convert_texts_to_indices(texts=titles,word2idx=word_2_idx,pad_idx=pad_idx)\n",
    "        titles_batch = titles_batch.to(DEVICE)\n",
    "        out = model(titles_batch)\n",
    "        loss = criterion(out, labels)\n",
    "        val_loss += loss.item()\n",
    "        # Convert the output with sigmoid \n",
    "        out = torch.sigmoid(out)\n",
    "        out = torch.round(out)\n",
    "        # Calculate the accuracy\n",
    "        for i in range(out.size(0)):\n",
    "            if torch.equal(out[i], labels[i]):\n",
    "                correct += 1\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(\"Validation loss: {}\".format(round(val_loss/len(val_loader),4)))\n",
    "print(\"Validation accuracy: {}\".format(round(correct/total,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Riccardo\\miniconda3\\envs\\labs2024\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Riccardo\\miniconda3\\envs\\labs2024\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "target_labels = dataset.labels\n",
    "id2label = {i:label for i, label in enumerate(target_labels)}\n",
    "label2id = {label:i for i, label in enumerate(target_labels)}\n",
    "# Model \n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased\", \n",
    "                                                           problem_type=\"multi_label_classification\", \n",
    "                                                           num_labels=len(target_labels),\n",
    "                                                           id2label=id2label,\n",
    "                                                           label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 4614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/590 [00:00<?, ?it/s]c:\\Users\\Riccardo\\miniconda3\\envs\\labs2024\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "  1%|‚ñè         | 8/590 [01:20<1:38:12, 10.12s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 52\u001b[0m\n\u001b[0;32m     49\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     50\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 52\u001b[0m     train_loss\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining loss: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mround\u001b[39m(train_loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader),\u001b[38;5;241m4\u001b[39m)))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from utils import convert_texts_to_indices_bert\n",
    "from tqdm import tqdm\n",
    "\n",
    "# TRAIN LOOP \n",
    "# HYPERPARAMETERS\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "## FREEZE THE WHOLE NETWORK ASIDE THE CLASSIFICATION LAYER\n",
    "for name, param in model.named_parameters():\n",
    "    if 'classifier' not in name:\n",
    "        param.requires_grad = False\n",
    "\n",
    "print(\"Model parameters: {}\".format(sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
    "\n",
    "# Send the model to the GPU \n",
    "model.to(DEVICE)\n",
    "\n",
    "# Create the dataloaders\n",
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)\n",
    "\n",
    "# Create the optimizer\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "\n",
    "# Create the loss function\n",
    "import torch.nn as nn\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Send the model to the GPU\n",
    "model.train()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = 0\n",
    "    for batch in tqdm(train_loader):\n",
    "        titles, abst, labels = batch\n",
    "        labels = labels.to(DEVICE)\n",
    "        # Prepare the titles\n",
    "        titles_batch = convert_texts_to_indices_bert(texts=titles,max_len=512)\n",
    "        input_ids = titles_batch['input_ids'].to(DEVICE)\n",
    "        attention_mask = titles_batch['attention_mask'].to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = out.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss+=loss.item()\n",
    "     \n",
    "    print(\"Training loss: {}\".format(round(train_loss/len(train_loader),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labs2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
