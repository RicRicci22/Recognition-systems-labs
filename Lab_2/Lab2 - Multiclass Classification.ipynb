{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":437,"status":"ok","timestamp":1677660520150,"user":{"displayName":"Riccardo Ricci","userId":"11679554425713061537"},"user_tz":-60},"id":"Qi3PLeMHmtrt","outputId":"a957672d-311f-41a7-f459-235be0f1d74e"},"outputs":[],"source":["!kaggle datasets list"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!kaggle datasets list -s flowers"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Download the dataset\n","!kaggle datasets download -d alxmamaev/flowers-recognition"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19810,"status":"ok","timestamp":1677660578876,"user":{"displayName":"Riccardo Ricci","userId":"11679554425713061537"},"user_tz":-60},"id":"s9jKI4qAjXVn","outputId":"4ec09bff-6f12-4134-8a47-ff8f31e95e90"},"outputs":[],"source":["# Unzip the dataset\n","!tar -xf flowers-recognition.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1677660578877,"user":{"displayName":"Riccardo Ricci","userId":"11679554425713061537"},"user_tz":-60},"id":"IHUUKC3HptEW"},"outputs":[],"source":["# Import modules\n","import os\n","from PIL import Image\n","import random\n","import matplotlib.pyplot as plt "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":862},"executionInfo":{"elapsed":8435,"status":"ok","timestamp":1677660599389,"user":{"displayName":"Riccardo Ricci","userId":"11679554425713061537"},"user_tz":-60},"id":"sKwkyeobppL7","outputId":"cac40e97-755c-4d1f-a3dd-3f5385f1a1f0"},"outputs":[],"source":["# Explore the data\n","fig = plt.figure(figsize=(15,15)) \n","tot_images = 20\n","num_images_for_each = 4\n","for num_folder, folder in enumerate(os.listdir(\"flowers\")):\n","    print(\"Number of images of \", folder,\":\",len(os.listdir(\"flowers/\" + folder)))\n","    files = os.listdir(\"flowers/\" + folder)\n","    random.shuffle(files)\n","    for num, fn in enumerate(files[:num_images_for_each]):\n","        path = os.path.join(\"flowers/\" + folder,fn)\n","        img = Image.open(path)\n","        plt.subplot(tot_images//4,4,num_folder*4+num+1)\n","        plt.title(folder)\n","        plt.axis('off')\n","        plt.imshow(img)\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Let's try our first attempt with the Plain-CNN that we defined last time! "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from model import PlainCNN\n","import torch\n","\n","# Test the network \n","model = PlainCNN([1,2,2,2,2], 5)\n","model.test_forward(torch.randn(1,3,224,224))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from train_utils import train\n","from torch.optim import SGD\n","from torch.nn import CrossEntropyLoss\n","import torchvision.transforms as transf\n","from dataset import FlowerDataset, get_train_val_loaders, split_dataset\n","\n","# Define the transformations \n","transforms_train = transf.Compose([\n","                            transf.Resize((224,224), antialias=True), \n","                            transf.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","                            ])\n","transforms_test_val = transf.Compose([\n","                            transf.Resize((224,224), antialias=True), \n","                            transf.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","                            ])\n","\n","train_images, val_images, test_images = split_dataset(\"flowers\", train_proportion=0.8, val_proportion=0.1)\n","\n","trainset = FlowerDataset(train_images, transforms_train)\n","valset = FlowerDataset(val_images, transforms_test_val)\n","\n","trainloader, valloader = get_train_val_loaders(trainset, valset, batch_size=8)\n","\n","# Use cuda if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Get the model \n","model = PlainCNN([1,4,4,4,4], n_classes=5)\n","model.to(device)\n","\n","print(\"Tot model parameters:\", sum([param.numel() for param in model.parameters()]))\n","print(\"Trainable model parameters:\", sum([param.numel() for param in model.parameters() if param.requires_grad]))\n","\n","# Hyperparameters \n","learning_rate = 5e-3\n","epochs = 1\n","\n","# Get the optimizer\n","optimizer = SGD(model.parameters(),lr=learning_rate, weight_decay=1e-4, momentum=0.9)\n","\n","# Get the loss function \n","loss_fn = CrossEntropyLoss(reduction=\"mean\")\n","\n","# Call the train function\n","train(model=model, \n","      trainloader=trainloader, \n","      valloader=valloader, \n","      epochs=epochs, \n","      optimizer=optimizer,\n","      loss_fn=loss_fn,\n","      device=device,\n","      save_directory=model._getname_())"]},{"cell_type":"markdown","metadata":{},"source":["### TEST ON SOME IMAGES"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from dataset import FlowerDataset\n","from dataset import get_test_loader\n","import os\n","\n","# Load the weights of the network \n","model = PlainCNN([1,4,4,4,4], n_classes=5)\n","model.load_state_dict(torch.load(os.path.join(model._getname_(),\"model_1_epochs.pt\")))\n","\n","fig = plt.figure(figsize=(15,15))\n","num_images = 16\n","testset = FlowerDataset(test_images, None)\n","testloader = get_test_loader(testset, batch_size=1)\n","testloader = iter(testloader)\n","\n","model.eval()\n","with torch.no_grad():\n","  for i in range(num_images):\n","    image, label = next(testloader)\n","    # Apply transformation on image\n","    image_transf = transforms_test_val(image)\n","    out = model(image_transf)\n","    prediction = out.argmax(1)\n","    plt.subplot(num_images//4,4,i+1)\n","    plt.axis('off')\n","    plt.imshow(image.squeeze().moveaxis(0,-1))\n","    if(prediction.item()==0):\n","      plt.title(\"This is a daisy!\\n\")\n","    elif (prediction.item()==1):\n","      plt.title(\"This is a dandelion!\\n\")\n","    elif (prediction.item()==2):\n","      plt.title(\"This is a rose!\\n\")\n","    elif (prediction.item()==3):\n","      plt.title(\"This is a sunflower!\\n\")\n","    elif(prediction.item()==4):\n","      plt.title(\"This is a tulip!\\n\")\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from tqdm import tqdm \n","\n","# Let's calculate the accuracy on the test set \n","testset = FlowerDataset(test_images, transforms_test_val)\n","testloader = get_test_loader(testset, batch_size=8)\n","loss_fn = CrossEntropyLoss(reduction=\"mean\")\n","# Put the model in evaluation mode\n","model.eval()\n","# Send the model to the device\n","model.to(device)\n","with torch.no_grad():\n","    loss_test = 0 \n","    accuracy_test = 0\n","    for i, data in enumerate(tqdm(testloader)):\n","        imgs, labels = data \n","        # Send data to device\n","        imgs = imgs.to(device)\n","        labels = labels.to(device)\n","        # Predict\n","        predictions = model(imgs)\n","        loss = loss_fn(predictions,labels)\n","        loss_test += loss.item()\n","        accuracy_test += (sum(predictions.argmax(1)==labels)/imgs.shape[0]).item()\n","        \n","print(\"\\nTest loss:\",loss_test/len(testloader))\n","print(\"Test accuracy:\",accuracy_test/len(testloader))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# NOW LET'S TRY WITH SKIP CNN!"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Let's see if the number of parameters is the same as the resnet18 from pytorch!\n","\n","from torchvision.models import resnet18\n","from model import SkipCNN\n","import torch.nn as nn\n","\n","resnet = resnet18()\n","resnet.fc = nn.Linear(512,5)\n","\n","print(\"Parameters of the ResNet18 model:\", sum([param.numel() for param in resnet.parameters()]))\n","\n","model = SkipCNN([1,2,2,2,2], n_classes=5)\n","\n","print(\"Parameters of the SkipCNN model:\", sum([param.numel() for param in model.parameters()]))\n","\n","del model\n","del resnet"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from train_utils import train\n","from torch.optim import SGD\n","from torch.nn import CrossEntropyLoss\n","import torchvision.transforms as transf\n","from dataset import FlowerDataset, get_train_val_loaders, split_dataset\n","\n","# Define the transformations \n","transforms_train = transf.Compose([\n","                            transf.Resize((224,224), antialias=True), \n","                            transf.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","                            ])\n","transforms_test_val = transf.Compose([\n","                            transf.Resize((224,224), antialias=True), \n","                            transf.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","                            ])\n","\n","train_images, val_images, test_images = split_dataset(\"flowers\", train_proportion=0.8, val_proportion=0.1)\n","\n","trainset = FlowerDataset(train_images, transforms_train)\n","valset = FlowerDataset(val_images, transforms_test_val)\n","\n","trainloader, valloader = get_train_val_loaders(trainset, valset, batch_size=8)\n","\n","# Use cuda if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Get the model \n","model = SkipCNN([1,2,2,2,2], n_classes=5)\n","model.to(device)\n","\n","print(\"Tot model parameters:\", sum([param.numel() for param in model.parameters()]))\n","print(\"Trainable model parameters:\", sum([param.numel() for param in model.parameters() if param.requires_grad]))\n","\n","# Hyperparameters \n","learning_rate = 5e-3\n","epochs = 1\n","\n","# Get the optimizer\n","optimizer = SGD(model.parameters(),lr=learning_rate, weight_decay=1e-4, momentum=0.9)\n","\n","# Get the loss function \n","loss_fn = CrossEntropyLoss(reduction=\"mean\")\n","\n","# Call the train function\n","train(model=model, \n","      trainloader=trainloader, \n","      valloader=valloader, \n","      epochs=epochs, \n","      optimizer=optimizer,\n","      loss_fn=loss_fn,\n","      device=device,\n","      save_directory=model._getname_())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from dataset import FlowerDataset\n","from dataset import get_test_loader\n","import os\n","\n","# Load the weights of the network \n","model = SkipCNN([1,2,2,2,2], n_classes=5)\n","model.load_state_dict(torch.load(os.path.join(model._getname_(),\"model_1_epochs.pt\")))\n","\n","fig = plt.figure(figsize=(15,15))\n","num_images = 16\n","testset = FlowerDataset(test_images, None)\n","testloader = get_test_loader(testset, batch_size=1)\n","testloader = iter(testloader)\n","\n","model.eval()\n","with torch.no_grad():\n","  for i in range(num_images):\n","    image, label = next(testloader)\n","    # Apply transformation on image\n","    image_transf = transforms_test_val(image)\n","    out = model(image_transf)\n","    prediction = out.argmax(1)\n","    plt.subplot(num_images//4,4,i+1)\n","    plt.axis('off')\n","    plt.imshow(image.squeeze().moveaxis(0,-1))\n","    if(prediction.item()==0):\n","      plt.title(\"This is a daisy!\\n\")\n","    elif (prediction.item()==1):\n","      plt.title(\"This is a dandelion!\\n\")\n","    elif (prediction.item()==2):\n","      plt.title(\"This is a rose!\\n\")\n","    elif (prediction.item()==3):\n","      plt.title(\"This is a sunflower!\\n\")\n","    elif(prediction.item()==4):\n","      plt.title(\"This is a tulip!\\n\")\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Let's calculate the accuracy on the test set \n","testset = FlowerDataset(test_images, transforms_test_val)\n","testloader = get_test_loader(testset, batch_size=8)\n","loss_fn = CrossEntropyLoss(reduction=\"mean\")\n","# Put the model in evaluation mode\n","model.eval()\n","# Send the model to the device\n","model.to(device)\n","with torch.no_grad():\n","    loss_test = 0 \n","    accuracy_test = 0\n","    for i, data in enumerate(tqdm(testloader)):\n","        imgs, labels = data \n","        # Send data to device\n","        imgs = imgs.to(device)\n","        labels = labels.to(device)\n","        # Predict\n","        predictions = model(imgs)\n","        loss = loss_fn(predictions,labels)\n","        loss_test += loss.item()\n","        accuracy_test += (sum(predictions.argmax(1)==labels)/imgs.shape[0]).item()\n","        \n","print(\"\\nTest loss:\",loss_test/len(testloader))\n","print(\"Test accuracy:\",accuracy_test/len(testloader))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Do it with transfer learning "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from train_utils import train\n","from torch.optim import SGD\n","from torch.nn import CrossEntropyLoss\n","import torchvision.transforms as transf\n","from dataset import FlowerDataset, get_train_val_loaders, split_dataset\n","from torchvision.models import resnet18, ResNet18_Weights\n","\n","# Define the transformations \n","transforms_train = transf.Compose([\n","                            transf.Resize((224,224), antialias=True), \n","                            transf.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","                            ])\n","transforms_test_val = transf.Compose([\n","                            transf.Resize((224,224), antialias=True), \n","                            transf.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","                            ])\n","\n","train_images, val_images, test_images = split_dataset(\"flowers\", train_proportion=0.8, val_proportion=0.1)\n","\n","trainset = FlowerDataset(train_images, transforms_train)\n","valset = FlowerDataset(val_images, transforms_test_val)\n","\n","trainloader, valloader = get_train_val_loaders(trainset, valset, batch_size=8)\n","\n","# Use cuda if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Get the model \n","model = resnet18(weights=ResNet18_Weights.DEFAULT)\n","# Modify the last classification layer \n","model.fc = nn.Linear(512,5)\n","# Freeze all except the last layer\n","for name, param in model.named_parameters():\n","    if \"fc\" not in name:\n","        param.requires_grad = False\n","    \n","model.to(device)\n","\n","print(\"Tot model parameters:\", sum([param.numel() for param in model.parameters()]))\n","print(\"Trainable model parameters:\", sum([param.numel() for param in model.parameters() if param.requires_grad]))\n","\n","# Hyperparameters \n","learning_rate = 5e-3\n","epochs = 1\n","\n","# Get the optimizer\n","optimizer = SGD(model.parameters(),lr=learning_rate, weight_decay=1e-4, momentum=0.9)\n","\n","# Get the loss function \n","loss_fn = CrossEntropyLoss(reduction=\"mean\")\n","\n","# Call the train function\n","train(model=model, \n","      trainloader=trainloader, \n","      valloader=valloader, \n","      epochs=epochs, \n","      optimizer=optimizer,\n","      loss_fn=loss_fn,\n","      device=device,\n","      save_directory=\"Resnet18_Linear_Probing\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from dataset import FlowerDataset\n","from dataset import get_test_loader\n","import os\n","\n","# Load the network with random initialized weights\n","model = resnet18()\n","# Modify the last classification layer \n","model.fc = nn.Linear(512,5)\n","model.load_state_dict(torch.load(os.path.join(\"Resnet18_Linear_Probing\",\"model_1_epochs.pt\")))\n","\n","fig = plt.figure(figsize=(15,15))\n","num_images = 16\n","testset = FlowerDataset(test_images, None)\n","testloader = get_test_loader(testset, batch_size=1)\n","testloader = iter(testloader)\n","\n","model.eval()\n","with torch.no_grad():\n","  for i in range(num_images):\n","    image, label = next(testloader)\n","    # Apply transformation on image\n","    image_transf = transforms_test_val(image)\n","    out = model(image_transf)\n","    prediction = out.argmax(1)\n","    plt.subplot(num_images//4,4,i+1)\n","    plt.axis('off')\n","    plt.imshow(image.squeeze().moveaxis(0,-1))\n","    if(prediction.item()==0):\n","      plt.title(\"This is a daisy!\\n\")\n","    elif (prediction.item()==1):\n","      plt.title(\"This is a dandelion!\\n\")\n","    elif (prediction.item()==2):\n","      plt.title(\"This is a rose!\\n\")\n","    elif (prediction.item()==3):\n","      plt.title(\"This is a sunflower!\\n\")\n","    elif(prediction.item()==4):\n","      plt.title(\"This is a tulip!\\n\")\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Let's calculate the accuracy on the test set \n","testset = FlowerDataset(test_images, transforms_test_val)\n","testloader = get_test_loader(testset, batch_size=8)\n","loss_fn = CrossEntropyLoss(reduction=\"mean\")\n","# Put the model in evaluation mode\n","model.eval()\n","# Send the model to the device\n","model.to(device)\n","with torch.no_grad():\n","    loss_test = 0 \n","    accuracy_test = 0\n","    for i, data in enumerate(tqdm(testloader)):\n","        imgs, labels = data \n","        # Send data to device\n","        imgs = imgs.to(device)\n","        labels = labels.to(device)\n","        # Predict\n","        predictions = model(imgs)\n","        loss = loss_fn(predictions,labels)\n","        loss_test += loss.item()\n","        accuracy_test += (sum(predictions.argmax(1)==labels)/imgs.shape[0]).item()\n","        \n","print(\"\\nTest loss:\",loss_test/len(testloader))\n","print(\"Test accuracy:\",accuracy_test/len(testloader))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from train_utils import train\n","from torch.optim import SGD\n","import torch\n","import torch.nn as nn\n","from torch.nn import CrossEntropyLoss\n","import torchvision.transforms as transf\n","from dataset import FlowerDataset, get_train_val_loaders, split_dataset\n","from torchvision.models import resnet50, ResNet50_Weights\n","\n","# Define the transformations \n","transforms_train = transf.Compose([\n","                            transf.Resize((224,224), antialias=True), \n","                            transf.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","                            ])\n","transforms_test_val = transf.Compose([\n","                            transf.Resize((224,224), antialias=True), \n","                            transf.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","                            ])\n","\n","train_images, val_images, test_images = split_dataset(\"flowers\", train_proportion=0.8, val_proportion=0.1)\n","\n","trainset = FlowerDataset(train_images, transforms_train)\n","valset = FlowerDataset(val_images, transforms_test_val)\n","\n","trainloader, valloader = get_train_val_loaders(trainset, valset, batch_size=8)\n","\n","# Use cuda if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Get the model \n","model = resnet50(weights=ResNet50_Weights.DEFAULT)\n","# Modify the last classification layer \n","model.fc = nn.Linear(2048,5)\n","# Freeze all except the last layer\n","for name, param in model.named_parameters():\n","    if \"fc\" not in name:\n","        param.requires_grad = False\n","    \n","model.to(device)\n","\n","print(\"Tot model parameters:\", sum([param.numel() for param in model.parameters()]))\n","print(\"Trainable model parameters:\", sum([param.numel() for param in model.parameters() if param.requires_grad]))\n","\n","# Hyperparameters \n","learning_rate = 5e-3\n","epochs = 1\n","\n","# Get the optimizer\n","optimizer = SGD(model.parameters(),lr=learning_rate, weight_decay=1e-4, momentum=0.9)\n","\n","# Get the loss function \n","loss_fn = CrossEntropyLoss(reduction=\"mean\")\n","\n","# Call the train function\n","train(model=model, \n","      trainloader=trainloader, \n","      valloader=valloader, \n","      epochs=epochs, \n","      optimizer=optimizer,\n","      loss_fn=loss_fn,\n","      device=device,\n","      save_directory=\"Resnet50_Linear_Probing\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from dataset import FlowerDataset\n","from dataset import get_test_loader\n","import os\n","\n","# Load the weights of the network \n","model = resnet50()\n","# Modify the last classification layer \n","model.fc = nn.Linear(2048,5)\n","model.load_state_dict(torch.load(os.path.join(\"Resnet50_Linear_Probing\",\"model_1_epochs.pt\")))\n","\n","fig = plt.figure(figsize=(15,15))\n","num_images = 16\n","testset = FlowerDataset(test_images, None)\n","testloader = get_test_loader(testset, batch_size=1)\n","testloader = iter(testloader)\n","\n","model.eval()\n","with torch.no_grad():\n","  for i in range(num_images):\n","    image, label = next(testloader)\n","    # Apply transformation on image\n","    image_transf = transforms_test_val(image)\n","    out = model(image_transf)\n","    prediction = out.argmax(1)\n","    plt.subplot(num_images//4,4,i+1)\n","    plt.axis('off')\n","    plt.imshow(image.squeeze().moveaxis(0,-1))\n","    if(prediction.item()==0):\n","      plt.title(\"This is a daisy!\\n\")\n","    elif (prediction.item()==1):\n","      plt.title(\"This is a dandelion!\\n\")\n","    elif (prediction.item()==2):\n","      plt.title(\"This is a rose!\\n\")\n","    elif (prediction.item()==3):\n","      plt.title(\"This is a sunflower!\\n\")\n","    elif(prediction.item()==4):\n","      plt.title(\"This is a tulip!\\n\")\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from tqdm import tqdm\n","\n","# Let's calculate the accuracy on the test set \n","testset = FlowerDataset(test_images, transforms_test_val)\n","testloader = get_test_loader(testset, batch_size=8)\n","loss_fn = CrossEntropyLoss(reduction=\"mean\")\n","# Put the model in evaluation mode\n","model.eval()\n","# Send the model to the device\n","model.to(device)\n","with torch.no_grad():\n","    loss_test = 0 \n","    accuracy_test = 0\n","    for i, data in enumerate(tqdm(testloader)):\n","        imgs, labels = data \n","        # Send data to device\n","        imgs = imgs.to(device)\n","        labels = labels.to(device)\n","        # Predict\n","        predictions = model(imgs)\n","        loss = loss_fn(predictions,labels)\n","        loss_test += loss.item()\n","        accuracy_test += (sum(predictions.argmax(1)==labels)/imgs.shape[0]).item()\n","        \n","print(\"\\nTest loss:\",loss_test/len(testloader))\n","print(\"Test accuracy:\",accuracy_test/len(testloader))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from train_utils import train\n","from torch.optim import SGD\n","import torch\n","import torch.nn as nn\n","from torch.nn import CrossEntropyLoss\n","import torchvision.transforms as transf\n","from dataset import FlowerDataset, get_train_val_loaders, split_dataset\n","from torchvision.models import resnet101, ResNet101_Weights\n","\n","# Define the transformations \n","transforms_train = transf.Compose([\n","                            transf.Resize((224,224), antialias=True), \n","                            transf.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","                            ])\n","transforms_test_val = transf.Compose([\n","                            transf.Resize((224,224), antialias=True), \n","                            transf.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","                            ])\n","\n","train_images, val_images, test_images = split_dataset(\"flowers\", train_proportion=0.8, val_proportion=0.1)\n","\n","trainset = FlowerDataset(train_images, transforms_train)\n","valset = FlowerDataset(val_images, transforms_test_val)\n","\n","trainloader, valloader = get_train_val_loaders(trainset, valset, batch_size=8)\n","\n","# Use cuda if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Get the model \n","model = resnet101(weights=ResNet101_Weights.DEFAULT)\n","# Modify the last classification layer \n","model.fc = nn.Linear(2048,5)\n","# Freeze all except the last layer\n","for name, param in model.named_parameters():\n","    if \"fc\" not in name:\n","        param.requires_grad = False\n","    \n","model.to(device)\n","\n","print(\"Tot model parameters:\", sum([param.numel() for param in model.parameters()]))\n","print(\"Trainable model parameters:\", sum([param.numel() for param in model.parameters() if param.requires_grad]))\n","\n","# Hyperparameters \n","learning_rate = 5e-3\n","epochs = 1\n","\n","# Get the optimizer\n","optimizer = SGD(model.parameters(),lr=learning_rate, weight_decay=1e-4, momentum=0.9)\n","\n","# Get the loss function \n","loss_fn = CrossEntropyLoss(reduction=\"mean\")\n","\n","# Call the train function\n","train(model=model, \n","      trainloader=trainloader, \n","      valloader=valloader, \n","      epochs=epochs, \n","      optimizer=optimizer,\n","      loss_fn=loss_fn,\n","      device=device,\n","      save_directory=\"Resnet101_Linear_Probing\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# Load the weights of the network \n","model = resnet101()\n","# Modify the last classification layer \n","model.fc = nn.Linear(2048,5)\n","model.load_state_dict(torch.load(os.path.join(\"Resnet101_Linear_Probing\",\"model_1_epochs.pt\")))\n","\n","fig = plt.figure(figsize=(15,15))\n","num_images = 16\n","train_images, val_images, test_images = split_dataset(\"flowers\", train_proportion=0.8, val_proportion=0.1)\n","testset = FlowerDataset(test_images, None)\n","\n","testloader = get_test_loader(testset, batch_size=1)\n","testloader = iter(testloader)\n","\n","model.eval()\n","with torch.no_grad():\n","  for i in range(num_images):\n","    image, label = next(testloader)\n","    # Apply transformation on image\n","    image_transf = transforms_test_val(image)\n","    out = model(image_transf)\n","    prediction = out.argmax(1)\n","    plt.subplot(num_images//4,4,i+1)\n","    plt.axis('off')\n","    plt.imshow(image.squeeze().moveaxis(0,-1))\n","    if(prediction.item()==0):\n","      plt.title(\"This is a daisy!\\n\")\n","    elif (prediction.item()==1):\n","      plt.title(\"This is a dandelion!\\n\")\n","    elif (prediction.item()==2):\n","      plt.title(\"This is a rose!\\n\")\n","    elif (prediction.item()==3):\n","      plt.title(\"This is a sunflower!\\n\")\n","    elif(prediction.item()==4):\n","      plt.title(\"This is a tulip!\\n\")\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from tqdm import tqdm\n","\n","# Let's calculate the accuracy on the test set \n","testset = FlowerDataset(test_images, transforms_test_val)\n","testloader = get_test_loader(testset, batch_size=8)\n","loss_fn = CrossEntropyLoss(reduction=\"mean\")\n","# Put the model in evaluation mode\n","model.eval()\n","# Send the model to the device\n","model.to(device)\n","with torch.no_grad():\n","    loss_test = 0 \n","    accuracy_test = 0\n","    for i, data in enumerate(tqdm(testloader)):\n","        imgs, labels = data \n","        # Send data to device\n","        imgs = imgs.to(device)\n","        labels = labels.to(device)\n","        # Predict\n","        predictions = model(imgs)\n","        loss = loss_fn(predictions,labels)\n","        loss_test += loss.item()\n","        accuracy_test += (sum(predictions.argmax(1)==labels)/imgs.shape[0]).item()\n","        \n","print(\"\\nTest loss:\",loss_test/len(testloader))\n","print(\"Test accuracy:\",accuracy_test/len(testloader))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from tqdm import tqdm\n","\n","# Let's calculate the accuracy on the test set \n","testset = FlowerDataset(test_images, transforms_test_val)\n","testloader = get_test_loader(testset, batch_size=8)\n","loss_fn = CrossEntropyLoss(reduction=\"mean\")\n","# Put the model in evaluation mode\n","model.eval()\n","# Send the model to the device\n","model.to(device)\n","with torch.no_grad():\n","    loss_test = 0 \n","    accuracy_test = 0\n","    for i, data in enumerate(tqdm(testloader)):\n","        imgs, labels = data \n","        # Send data to device\n","        imgs = imgs.to(device)\n","        labels = labels.to(device)\n","        # Predict\n","        predictions = model(imgs)\n","        loss = loss_fn(predictions,labels)\n","        loss_test += loss.item()\n","        accuracy_test += (sum(predictions.argmax(1)==labels)/imgs.shape[0]).item()\n","        \n","print(\"\\nTest loss:\",loss_test/len(testloader))\n","print(\"Test accuracy:\",accuracy_test/len(testloader))"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMBMOdwLn83pc4CCsHogsnV","mount_file_id":"18d5LXhD-HFqZNbPwpVHP7Lwh6PzFPS3p","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"newnlpt","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"undefined.undefined.undefined"},"vscode":{"interpreter":{"hash":"8ac9e49d44b760bd93688ef99a9561cf0cd875fa001e5a2bed6c9672b8b9b17d"}}},"nbformat":4,"nbformat_minor":0}
